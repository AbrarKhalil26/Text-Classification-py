{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "euv_oiIli9ti"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ljOfz4yYjNwc"
      },
      "outputs": [],
      "source": [
        "# moviereviews.tsv\n",
        "# ar_reviews_100k.tsv\n",
        "df = pd.read_csv('moviereviews.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwZPwsYZj_Wu",
        "outputId": "92fdb684-082c-44e4-a218-ce3bf73d6b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     label                                             review\n",
            "0      neg  how do films like mouse hunt get into theatres...\n",
            "1      neg  some talented actresses are blessed with a dem...\n",
            "2      pos  this has been an extraordinary year for austra...\n",
            "3      pos  according to hollywood movies made in last few...\n",
            "4      neg  my first press screening of 1998 and already i...\n",
            "...    ...                                                ...\n",
            "1995   pos  i like movies with albert brooks , and i reall...\n",
            "1996   pos  it might surprise some to know that joel and e...\n",
            "1997   pos  the verdict : spine-chilling drama from horror...\n",
            "1998   pos  i want to correct what i wrote in a former ret...\n",
            "1999   pos  a couple of months ago , when i first download...\n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hca2fMsOkIo4",
        "outputId": "3971247e-c5f7-439e-b468-99bcd48aba2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label      0\n",
              "review    35\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-Y_u3_MFjsOw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1965"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FSVHC6hErkM",
        "outputId": "e4c48be8-8a8b-40cc-80a7-f607798a1863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 blanks:  [57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
          ]
        }
      ],
      "source": [
        "blanks = []\n",
        "\n",
        "for i, label, reviews in df.itertuples():\n",
        "  if type (reviews) == str:\n",
        "    if reviews.isspace():\n",
        "      blanks.append(i)\n",
        "\n",
        "print(len(blanks), 'blanks: ', blanks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsOK1YMJfE_E",
        "outputId": "68656a59-4419-4d1b-aebf-3f58dcad20ab"
      },
      "outputs": [],
      "source": [
        "df.drop(blanks, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P4zpzO70kjsb"
      },
      "outputs": [],
      "source": [
        "X = df['review']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y6eGg12dlHrC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7640625\n",
            "Classification Report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.69      0.93      0.79       308\n",
            "         pos       0.91      0.61      0.73       332\n",
            "\n",
            "    accuracy                           0.76       640\n",
            "   macro avg       0.80      0.77      0.76       640\n",
            "weighted avg       0.80      0.76      0.76       640\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
        "text_clf_nb.fit(X_train, y_train)\n",
        "predictions = text_clf_nb.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy : {metrics.accuracy_score(y_test, predictions)}\")\n",
        "print(\"Classification Report :\")\n",
        "print(metrics.classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_YHG-DLlddJ",
        "outputId": "7ba5663b-7ec2-435a-8fae-a4c613ea9580"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Abrar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.846875\n",
            "Classification Report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.84      0.84      0.84       308\n",
            "         pos       0.85      0.85      0.85       332\n",
            "\n",
            "    accuracy                           0.85       640\n",
            "   macro avg       0.85      0.85      0.85       640\n",
            "weighted avg       0.85      0.85      0.85       640\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])\n",
        "text_clf_lsvc.fit(X_train, y_train)\n",
        "predictions = text_clf_lsvc.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy : {metrics.accuracy_score(y_test, predictions)}\")\n",
        "print(\"Classification Report :\")\n",
        "print(metrics.classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
